{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2015/12/10-machine-learning-algorithms-explained-army-soldier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters).\n",
    "\n",
    "* It is a main task of EDA, and a common technique for statistical data analysis, used in many fields -\n",
    "    - pattern recognition\n",
    "    - image analysis\n",
    "    - information retrieval\n",
    "    - bioinformatics\n",
    "    - data compression\n",
    "    - computer graphics\n",
    "    - machine learning\n",
    "\n",
    "$$D = \\{x_i\\} \\ - \\ \\text{no} \\ y_i$$\n",
    "\n",
    "<img src=\"https://editor.analyticsvidhya.com/uploads/56854k%20means%20clustering.png\">\n",
    "\n",
    "**Credits** - Image from Internet\n",
    "\n",
    "* The main task in clustering is to group the data values on the basis of **\" similarity \"**.\n",
    "    - Similarity can be assumed not just in one context but many. Perhaps, it is more towards problem specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Clustering is unsupervised leaning because there are no $y_i$\n",
    "\n",
    "* Supervised is when we have a dataset which has $x_i$ and $y_i$ both.\n",
    "\n",
    "* Semi-supervised is when a small part of dataset has both $x_i$ and $y_i$ and large part has only $x_i$. It happens when cost of accuring $y_i$ is large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications (Clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* E-Commerce\n",
    "    - Customer grouping based on their purchasing behaviour\n",
    "        - Money\n",
    "        - Credit card\n",
    "        - Debit card\n",
    "        - product category\n",
    "        - zip code\n",
    "\n",
    "* Image Segmentation (grouping or clustering similar pixels)\n",
    "    - Computer Vision\n",
    "    - Image Processing\n",
    "    - Satellite Imagery Analysis\n",
    "\n",
    "* Amazon Food Reviews\n",
    "    - Sentiment Analysis\n",
    "    - NLP\n",
    "\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Intra-cluster → within the cluster\n",
    "    - the distance between any two points is small\n",
    "* Inter-cluster → acorss or between clusters\n",
    "    - the distance between any two points is large\n",
    "\n",
    "![cluster-metrics](https://user-images.githubusercontent.com/63333753/133963519-31bef7ae-933f-4f80-b141-bd2cb2d95525.png)\n",
    "\n",
    "> The above two are the basis on how we measure the effectiveness of a clustering analysis.\n",
    "\n",
    "**Dunn-Index**\n",
    "\n",
    "$$D = \\frac{\\text{max}_{(i, j)}d(i, j)}{max_{(k)}d^1(k)}$$\n",
    "\n",
    "* $k \\in \\{C_1, C_2, C_3, \\dots C_k\\}$\n",
    "* $d$ → distance between $C_i$ and $C_j$ (inter-cluster distance)\n",
    "* numerator → maximal inter cluster distance\n",
    "* $d^1$ → maximum distance between two points in a cluster (intra-cluster distance)\n",
    "\n",
    "> If $D$ is high, it implies good clustering else, not a good metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `k`-Means Clustering (Geometric Intuition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Popular and simple centroid clustering algorithm.\n",
    "\n",
    "* `k` represents total number of points.\n",
    "    - Hyperparameter (cross validation)\n",
    "\n",
    "![k-means-gi](https://user-images.githubusercontent.com/63333753/133965526-257aac1d-bf88-45c1-83ef-92ea724f7761.png)\n",
    "\n",
    "* $C_1, C_2, c_3$ → are the centroids of the respective clusters (mean of all the points in a cluster)\n",
    "\n",
    "    - $C_i = \\frac{1}{n} \\sum_{x_j \\in S_i} x_j$\n",
    "\n",
    "* $S_1, S_2, S_3$ → are the clusters\n",
    "\n",
    "    - $S_1 \\cap S_2 = \\phi$\n",
    "    - $S_2 \\cap S_3 = \\phi$\n",
    "    - $S_3 \\cap S_1 = \\phi$\n",
    "    - $S_1 \\cup S_2 \\cup S_3 = D$\n",
    "\n",
    "* Every data point is assigned to a cluster whose centroid is the closest.\n",
    "\n",
    "> The core idea of `k`-Means is to find the `k` central points and assign each point to a cluster by certains conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical Formulation of `k`-Means\n",
    "\n",
    "https://www.saedsayad.com/clustering_kmeans.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Once, if we find the clusters, it becomes easy to arrange the sets based on proximity.\n",
    "    * k-centroids : $C_1, C_2, \\dots, C_k \\implies \\forall_{(i, j)} \\ x_i \\in S_j$\n",
    "    * k-sets : $S_1, S_2, \\dots S_k \\implies \\forall_{(i, j)} \\ S_i \\cap S_j = \\phi$\n",
    "    \n",
    "    $$\\text{argmin}_{\\{C_1, \\dots, C_k\\}} = \\sum_{i=1}^k \\sum_{x \\in S_i} ||x - C_i||^2$$\n",
    "\n",
    "> To solve this optimization, we prefer to choose lloyd's algorithm which uses the approximations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `k`-Means Algorithm (Lloyd's)\n",
    "\n",
    "https://youtu.be/5I3Ei69I40s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialization\n",
    "    - randomly pick `k` points from $D$ and consider them as $C_1, \\dots, C_k$\n",
    "\n",
    "2. Assignment\n",
    "    - for each point $x_j$ in $D$ select the nearest centroid $C_j$ by computing the distance and thus add $x_i$ to set $S_j$\n",
    "\n",
    "3. Re-calculate centroid\n",
    "    - update the centroid as this → $C_j = \\frac{1}{|S_j|} \\sum_{\\{x_i \\in S_j\\}} x_i$\n",
    "\n",
    "4. Repeat $2$ and $3$ until convergence\n",
    "    - convergence → centroids don't change much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization Sensitivity\n",
    "\n",
    "https://cs.wmich.edu/alfuqaha/summer14/cs6530/lectures/ClusteringAnalysis.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `k`-Means has the problem of initialization of random `k` points. Or, one of the drawbacks of random initialization.\n",
    "    - the final result is sensitive or dependent on the `k` points that are been picked.\n",
    "\n",
    "**How to tackle this?**\n",
    "\n",
    "* Repeat `k`-Means multiple times with different initializations.\n",
    "    - pick the best clustering result based on smaller intra-cluster and larger inter-cluster distances.\n",
    "    - takes more computation effort\n",
    "\n",
    "* `k`-Means++\n",
    "    - it replaces the random initializations with a smart initializations scheme\n",
    "    - **procedure**\n",
    "        - pick the first centroid randomly → $C_1$ for $D$\n",
    "        - for each $x_i \\in D$ create a distribution such as $x_i \\rightarrow \\text{dist}^2(x_i, \\text{nearest-centroid}) \\implies d_i$\n",
    "        - pick a point from $\\{D - C_1\\}$ with a probability proportional to $d_i$ (probabilistic approach)\n",
    "        - continue this until you have `k`centroids\n",
    "\n",
    "> `k`-Means++ does get effected by outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `k`-Means has problems when clusters are of different\n",
    "    - sizes\n",
    "    - densities\n",
    "    - non-globular shapes\n",
    "\n",
    "* `k`-Means has problems when the data contains outliers.\n",
    "\n",
    "**Solutions**\n",
    "\n",
    "* One way is to use many clusters and (put them together - which is not easy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `k`-Medoids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `k`-Mean centroids cannot be interpretted as the centroid will not be a part of the dataset.\n",
    "\n",
    "* If we want the centroids to be interpretable, then we must prefer to have centroids to be part of the dataset.\n",
    "\n",
    "* For such cases, we use `k`-Medoids (popular algo to interpret centroids).\n",
    "    - Partitioning around medoids (PAM)\n",
    "    - **Initialization** : `k`-Means++ → probabilistic approach\n",
    "    - **Assignment** : closest medoid → $x_i \\in S_j$ if medoid_j is the closest medoid to $x_i$\n",
    "    - **Update / Recomputation** :\n",
    "        - swap each medoid point with non-medoid point\n",
    "        - if loss decreases, keep the swap; else undo the swap\n",
    "        \n",
    "        $$\\text{loss} = \\sum_{i=1}^k \\sum_{x \\in S_i} ||x - m_j||^2$$\n",
    "        \n",
    "        - if swap is successful (loss ↓), then redo the **Assignment** step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time & Space Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `k`-Means\n",
    "    - **Time** → $O(nkdi)$\n",
    "        - $n$ → number of points\n",
    "        - $k$ → number of clusters\n",
    "        - $d$ → dimensionality of the data\n",
    "        - $i$ → number of iterations\n",
    "        - typicall $k \\leq 10$ and $i \\leq 300$\n",
    "    - **Space** → $O(nd + kd)$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
