{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Featurization and Feature Engineering are one of the most important aspects of Machine Learning.\n",
    "    - Converting some type of data into a numerical vector. **Textual data** into numerical vector.\n",
    "    - Various featurizations are -\n",
    "        - BoW\n",
    "        - TFIDF\n",
    "        - AvgW2V\n",
    "        - TFIDFW2V\n",
    "    - **Categorical data**\n",
    "        - One Hot Encoding\n",
    "        - Mean Response Rate\n",
    "        - Response Coding by Probability\n",
    "    - **Time Series data**\n",
    "        - The data or information has time as one of the features. Heart rate data can be represented in the form of time-series data.\n",
    "        - Earthquake Tracking System\n",
    "        - Stock Market\n",
    "    - **Image data**\n",
    "        - Face detection\n",
    "        - Face recognition\n",
    "        - Vide → (Image data + time-series)\n",
    "    - **Database tables**\n",
    "        - Data stored in relation database in different tables.\n",
    "    - **Graph data**\n",
    "        - Graph analytics is another commonly used term, and it refers specifically to the process of analyzing data in a graph format using data points as nodes and relationships as edges.\n",
    "        - Recommend a friend in facebook.\n",
    "\n",
    "* There are tons of types of data and featurization is somethind that researchers have spent decades doing research on this field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series - Moving Window\n",
    "\n",
    "Simplest featurization technique for time-series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One snapshot of time is known as window.\n",
    "* Right window (measurement) depends on the problem statement and it is more domain specific.\n",
    "* Some methods are - \n",
    "    - Mean, Std-dev\n",
    "    - Medians, Quantiles\n",
    "    - Max and Min\n",
    "    - Max minus Min (max - min)\n",
    "    - Max divied by Min (max / min)\n",
    "    - Local minima and Local maxima\n",
    "    - Mean crossing\n",
    "    - Zero crossing\n",
    "    - All this have to be done in a snapshot of window\n",
    "* Domain specific knowledge is must to come up with important features in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier Decomposition / Fourier Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is a method to represent the time-series data.\n",
    "* **Frequency** - Frequency is just the inverse of time period. It is often represented as `f`. It is measured in `Hertz`.\n",
    "* **Amplitude** - The height of the wave is called an amplitude of the wave. It is often represented as `A`.\n",
    "* **Period** - The time for a wave to complete one oscillation is called a time period. It is often represented as `T`.\n",
    "* **Fourier Transformation** - Given a composite wave which is repeating, the process of decomposing the pattern into sum of multiple waves (sine waves) is called fourier transformation.\n",
    "\n",
    "<img src=\"https://i2.wp.com/blog.fossasia.org/wp-content/uploads/2017/07/image1-1.jpg\">\n",
    "<!-- <img src=\"https://thepracticaldev.s3.amazonaws.com/i/v1p6fhprekoheceqafw1.png\"> -->\n",
    "\n",
    "**Credits** - Image from Internet\n",
    "\n",
    "**Steps**\n",
    "\n",
    "* Decompose the repeated data into multiple sine waves.\n",
    "* Get the amplitude of each sine wave $f_i$.\n",
    "* Plot $f_i$ and $A_i$.\n",
    "* Represent $f_i$ and $A_i$ in vector form.\n",
    "* Fourier representation of the data.\n",
    "\n",
    "![fe-1](https://user-images.githubusercontent.com/63333753/126126908-50b8930b-480b-49c3-b17b-9d45e51b419b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The idea of DL is, given **huge amount of data** - it will automatically learn gives the best featurization for that data. These features are also known as **Deep Learnt Features**.\n",
    "\n",
    "* Works brilliantly for\n",
    "    - Time series data\n",
    "    - Text data\n",
    "    - Image data\n",
    "\n",
    "* **LSTM** - Long Short-Term Memory (LSTM) networks are a type of recurrent neural network capable of learning order dependence in sequence prediction problems. This is a behavior required in complex problem domains like machine translation, speech recognition, and more. LSTMs are a complex area of deep learning. This is extensively used for time-series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The best way to featurize images is to use DL - CNN.\n",
    "* Two types of image histograms -\n",
    "    - **Color Histograms**\n",
    "        - Separate the pixels based on the color and plot the histogram for each color.\n",
    "        - Get the frequency count and replace the pixel values with the count of occurrence.\n",
    "        - Merge the new pixels for each color.\n",
    "        - Thus, we can somehow use this featurization of detection.\n",
    "        - Color histograms cannot detect shapes.\n",
    "    - **Edge Histograms**\n",
    "        - Highly used to detect where an edge is in the whole image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT - Scale Invariant Feature Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Very popular in detecting objects in an image.\n",
    "* It detects **keypoints** which are mostly corners.\n",
    "* For every **keypoint** it creates a `128` dimentional vector\n",
    "\n",
    "<img src=\"https://courses.cs.washington.edu/courses/cse576/13sp/images/features.png\">\n",
    "\n",
    "* This technique is highly used for image search.\n",
    "* In the above example image, the left image is known as **query image** and the right image is known as **db image**.\n",
    "* Scale Invariance\n",
    "    - Invariance means - doesn't change much.\n",
    "    - The features do not change much even of the size of the images are different - **scale invariance**\n",
    "    - This is also called as rotational invariance.\n",
    "\n",
    "* SIFT works for both,\n",
    "    - When the scale of image is different (size).\n",
    "    - When the image is rotated (slightly).\n",
    "\n",
    "**Credits** - Image from Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL - CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convulutional Neural Networks.\n",
    "* Best featurization DL technique for image data. It automatically does featurization given that the data is huge.\n",
    "* It is almost used for every image related problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relational Data & Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data stored in various tables that are related to each other by a unique id.\n",
    "    - Oracle\n",
    "    - MySQL\n",
    "    - SQLServer\n",
    "* To obtain nice features for data stored in relational tables, along with SQL it is must to have domain knowledge.\n",
    "\n",
    "**Example for E-commerce**\n",
    "\n",
    "If a data is stored in tables, to obtain features in order to predict if a customer buys the product in a week, we can think of the features like -\n",
    "\n",
    "* Number of times the customer has viewed the product\n",
    "* Income details of the customer\n",
    "* Zipcode for geographical details\n",
    "* Similar product that the customer has viewed\n",
    "* Offer and discounts\n",
    "* Season of the year\n",
    "* Salary week\n",
    "\n",
    "This featurization is highly dependant on the domain knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph analytics is another commonly used term, and it refers specifically to the process of analyzing data in a graph format using data points as nodes and relationships as edges.\n",
    "\n",
    "![fe-graphs](https://user-images.githubusercontent.com/63333753/126270541-dba5f1fa-e719-4ba3-8550-d00ba6b030cf.png)\n",
    "\n",
    "The above graph is a social graph (facebook) where -\n",
    "\n",
    "* $u_i$ → vertex\n",
    "* Edge $(u_i, u_j)$ → friendship\n",
    "\n",
    "Given this data, if our task is to recommend new friends for a user $(u_i)$ - we can do it in the following ways -\n",
    "\n",
    "* We can look for number of mutual friends for $u_i$.\n",
    "    - more the number of mutual friends, higher is the chance recommend a friend.\n",
    "* The number of paths between users.\n",
    "    - more the number of paths, higher the change of being friends.\n",
    "\n",
    "The features that we get by applying the concepts of graph theory are known as graph theoretic features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicator Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Indicator variables are mostly binary.\n",
    "\n",
    "* If the data consists of `height` as a feature, then we can convert this feature into indicator variable by\n",
    "    - if `height` > 150 → `1`\n",
    "    - else if `height` <= 150 → `0`\n",
    "    - deciding the threshold to convert a feature into an indicator variable is again a `problem specific` matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is a logical extension for indicator variables.\n",
    "* It is also known as feature bucketing.\n",
    "* Instead of having the feature in binary values, we will have multiple indicators associated with multiple conditions.\n",
    "    - Again, find the right threshold is problem specific.\n",
    "    - We can use DT model to come up right threshold using gini-impurity or information gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is also known as logical two way interaction variables. We see that there is an interaction happening between two features.\n",
    "* We use logical operators to interact with more than one condition, and thus create a new feature.\n",
    "    - if (`height` < 150) and (`weight` < 60)\n",
    "        feature = 1\n",
    "    - ...\n",
    "* Apart from using logical operators, we can use numerical (arithematical operators).\n",
    "    - (`height` * `weight`)\n",
    "    - ...\n",
    "* Given a task, how do we come up with right interaction variables?\n",
    "    - We can use DT which are very handy. We will get right threshold values with which we can create interactive variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have a single feature, considering the problem statement, we can apply some mathematical transforms like -\n",
    "\n",
    "* $\\log(x), e^x$\n",
    "* $\\sqrt{x}, \\sqrt[3]{x}$\n",
    "* $x^2, x^3, x^w, \\dots$ → polynomial\n",
    "* $\\sin(x), \\cos(x), \\tan(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Specific Featurizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we have features say `f1`, `f2`, and `f3` and we want to predict `y` which is real-valued target, by domain knowledge if we know that `y` can be predicted by some linear combination of `f1`, `f2`, and `f3`. Definitely for this kind of problems linear models (linear regression) are better.\n",
    "    - In such cases, decision trees may not work very well.\n",
    "\n",
    "* If we know that `y` can predicted with the interactions of `f1` and `f2`, hence for this kind of problems it is appropriate to use `RF` and `DT`. This is all done by domain knowlege."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Orthogonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The more different (orthogonal) the features are, the better would the model perform.\n",
    "* Features that have high correlation amongst themselves irrespective having high correlation with the target variable, their overall impact to build a model will be less.\n",
    "* Features having correlatation with target variable and are not correlated with each other are good to build the model.\n",
    "    - the performance of such a model produces higher accuracies.\n",
    "* The errors ($y_i - \\hat{y_i}$) that we obtain from the model, we can create a new feature that are correlated with errors and thus re-train the model combining the new feature ultimately gives better results.\n",
    "    - be careful from overfitting the model.\n",
    "    - the new feature can be said as orthogonal (different) to all other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Slicing the data based on features is known as feature slicing.\n",
    "* After slicing the data, we apply different models to train the sliced data.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "* First train a model on the whole data.\n",
    "* Separate the errors based on category.\n",
    "* If error distributions are different, then split the data by category feature.\n",
    "* Build different models for sliced data.\n",
    "\n",
    "**Cases**\n",
    "\n",
    "* Each category should be different in their behaviour.\n",
    "* There has to be sufficient number of point for each slice of the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
