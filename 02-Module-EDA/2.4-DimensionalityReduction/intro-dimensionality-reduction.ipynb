{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction, or dimension reduction, is the transformation of data from a high-dimensional space into a low-dimensional space so that the low-dimensional representation retains some meaningful properties of the original data, ideally close to its intrinsic dimension.\n",
    "\n",
    "* `2D` & `3D` → Scatter Plot and other related plots\n",
    "* `4D`, `5D`, & `6D` → Pair Plots\n",
    "* `nD` → Dimensionality Reduction\n",
    "    - PCA (Principal Component Analysis)\n",
    "    - t-SNE (t-distributed Stochastic Neighborhood Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row and Column Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A row vector is a row of entires. It has `1` row and `n` columns.\n",
    "\n",
    "$$a = [a_1, a_2, a_3, \\dots, a_n]$$\n",
    "\n",
    "* A column vector is a column of entries. It has `1` column and `n` rows.\n",
    "<pre>\n",
    "x = [[x1],\n",
    "       [x2],\n",
    "       [x3],\n",
    "       ...,\n",
    "       [xn]]\n",
    "</pre>\n",
    "\n",
    "**Note**\n",
    "* By default, when someone says a vector, it means that it is a column vector. \n",
    "* The transpose of column vector is called a row vector. \n",
    "* Please refer to [wiki](https://en.wikipedia.org/wiki/Row_and_column_vectors) article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset is represented as $D = \\{x_i, y_i\\}$ where $X = x_i$ (independant variables or features) and $Y = y_i$ (target variable or dependant variable).\n",
    "\n",
    "<pre>\n",
    "For example\n",
    "-----------\n",
    "</pre>\n",
    "\n",
    "Iris data $\\implies$ <pre>\n",
    "                         [[PL],\n",
    "                          [PW],\n",
    "                          [SL],\n",
    "                          [SW]]\n",
    "                    </pre>\n",
    "which are features and <pre>[species]</pre> represents target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Column Normalization**\n",
    "    - Consider each $col$ from the dataset and find out $col_{min}$ and $col_{max}$.\n",
    "    - Compute $$col_i^1 = \\frac{(col_i - col_{min})}{(col_{max} - col_{min})}$$\n",
    "    - All the value of $col$ will be in the range of $0$ and $1$, $col_i^1 \\in [0, 1]$\n",
    "    - This helps to get rid off scale measurement.\n",
    "    - Squishes the data into one unit measurement.\n",
    "\n",
    "![geometric-norm](https://user-images.githubusercontent.com/63333753/113279562-e1a67e00-9300-11eb-8fd6-486684087ed1.png)\n",
    "\n",
    "* **Column Standardization**\n",
    "    - Consider each $col$ from the dataset and find out $\\mu_{col}$ and $\\sigma_{col}$.\n",
    "    - Compute standard normal variate for the $col$ such as $$col_{z} = \\frac{(col_i - \\mu_{col})}{\\sigma_{col}}$$\n",
    "    - The mean of $col_z$ is $0$ and standard deviation is $1$.\n",
    "    - It is also called as mean centering, i.e., mean is at origin and scaling is done by standard deviation (1).\n",
    "\n",
    "![geometric-standard](https://user-images.githubusercontent.com/63333753/113279342-97250180-9300-11eb-83d3-0b3d67d61cf0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-Variance Data Matrix (Symmetric Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $A$ be a matrix where $A_{ij} = A_{ji}$ then $A$ is known as symmetric matrix.\n",
    "\n",
    "<pre>\n",
    "A = [[2, 1, 2],\n",
    "     [1, 1, 5],\n",
    "     [2, 5, 3]]\n",
    "</pre>\n",
    "\n",
    "Co-Variance Data Matrix is a symmetric matrix.\n",
    "\n",
    "* $\\text{Cov(X, Y)} = \\frac{1}{(n - 1)} \\sum_{i=1}^n (x_i - \\mu_x)(y_i - \\mu_y)$\n",
    "* $\\text{Cov(X, X)} = Var(X)$\n",
    "* $\\text{Cov(X, Y)} = \\text{Cov(Y, X)}$\n",
    "\n",
    "Let $f_1$ and $f_2$ are two features which are `column standardized`. The $\\text{Cov}(f_1, f_2)$ is written as -\n",
    "\n",
    "$$\\implies \\frac{1}{(n-1)}\\sum_{i=1}^n f_1f_2$$\n",
    "$$\\implies \\frac{f_1^Tf_2}{(n-1)}$$\n",
    "\n",
    "**Note** - We consider $(n-1)$ so as to make sure we get an unbiased estimator.\n",
    "\n",
    "If $X$ is a dataset irrespective of target variable. Assuming $X$ is `column standardized`, we get covariance matrix as -\n",
    "\n",
    "$$S_{ij} = \\frac{X^TX}{(n-1)} = \\frac{f_i^Tf_j}{(n-1)}$$\n",
    "\n",
    "where\n",
    "* $f_i$ and $f_j$ are features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
