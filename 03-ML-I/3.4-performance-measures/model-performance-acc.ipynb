{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Accuracy} = \\frac{\\text{Number of correctly classified points}}{\\text{Total numner of points in} \\ D_{Test}}$$\n",
    "\n",
    "The accuracy value ranges between 0 and 1\n",
    "* 0 → very least performance\n",
    "* 1 → high performance\n",
    "\n",
    "**Pros**\n",
    "\n",
    "* Easy to understand the measure\n",
    "\n",
    "**Cons**\n",
    "\n",
    "* In the case of imbalanced data, the accuracy can be biased depending upon the `target_feature` which is large.\n",
    "* If we try to get the probability scores of two models,\n",
    "    - 1st model can give meaningful probabilities whereas 2nd model is opposite to 1st, but when measured the accuracy of these two models - it can be same. Down the line, we know which model is better.\n",
    "    - Accuracy has no access to proabability scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A `confusion matrix` is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known. \n",
    "\n",
    "* The confusion matrix itself is relatively simple to understand, but the related terminology can be confusing.\n",
    "\n",
    "* Principal diagonal elements of the matrix should always be high. This is an indication that the model is performing better.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/566/1*q2ozl-R0bxWXMwWmkERdsQ.png\">\n",
    "\n",
    "<img src=\"https://i.imgur.com/iGLkDOL.png\">\n",
    "\n",
    "**Credits** - Image from Internet\n",
    "\n",
    "From the above image we can get -\n",
    "\n",
    "* $\\text{n} = \\text{N} + \\text{P}$\n",
    "* $\\text{TPR} = \\frac{\\text{TP}}{\\text{P}}$\n",
    "* $\\text{TNR} = \\frac{\\text{TN}}{\\text{N}}$\n",
    "* $\\text{FPR} = \\frac{\\text{FP}}{\\text{N}}$\n",
    "* $\\text{FNR} = \\frac{\\text{FN}}{\\text{P}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision v/s Recall v/s F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Precision and Recall are often in information retrieval problems.\n",
    "\n",
    "* **Precision** → of all the points the model declared/predicted to be positve, but what is the percentage of them that are positive.\n",
    "\n",
    "$$\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$$\n",
    "\n",
    "* **Recall** → similar to TPR. Of all the actually positive points, how many of are predicted to be positive.\n",
    "\n",
    "$$\\text{Recall} = \\frac{\\text{TP}}{\\text{P}} = \\text{TPR} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$$\n",
    "\n",
    "> Precision and Recall mostly care about positive class.\n",
    "\n",
    "* **F1-Score** → is a one measure that combines both precision and recall (similar to harmonic mean formula).\n",
    "\n",
    "$$\\text{F1-Score} = 2 \\bigg[\\frac{\\text{Precision} * \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\bigg]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiver Operating Characteristic Curve (ROC) and Area Under this Curve (AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Take each probability score and consider it as a threshold and create a binary column.\n",
    "* We need to repeat this for all the predictions (scores).\n",
    "    - Whichever probability score is greater (close to 1) simply means that it is positive.\n",
    "* Compute `TPR` and `FPR` with respect to actual values and predictions based on threshold.\n",
    "* If we plot `TPR` and `FPR`, we get ROC curve. The area under this curve is AUC which is lies between 0 and 1.\n",
    "\n",
    "**Properties of AUC**\n",
    "\n",
    "* AUC will be high for imbalanced data.\n",
    "* AUC only cares about scores which are sorted in decreasing order.\n",
    "* AUC for any random binary classification model will be exactly 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpr = [0.  0.5 0.5 1.  1. ]\n",
      "fpr = [0.  0.  0.5 0.5 1. ]\n",
      "thresholds =  [1.8  0.8  0.4  0.35 0.1 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "y = np.array([0, 0, 1, 1])\n",
    "# remember you need to have scores as probabilities\n",
    "# scores = model.predict_proba(y)\n",
    "scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "fpr, tpr, thresholds = roc_curve(y, scores)\n",
    "\n",
    "print(\"tpr =\",tpr)\n",
    "print(\"fpr =\", fpr)\n",
    "print(\"thresholds = \",thresholds)\n",
    "\n",
    "plt.plot(fpr, tpr, 'o-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Log-Loss uses the actual probability scores.\n",
    "\n",
    "$$\\text{log-loss} = \\frac{-1}{n} \\sum_{i = 1}^n \\big\\{\\log(p_i)*y_i + (1-y_i)*\\log(1-p_i) \\big\\}$$\n",
    "\n",
    "* We want log-loss to be as small as possible.\n",
    "* It can lie between $0$ to $\\infty$.\n",
    "* Log-Loss is the most important classification metric based on probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-squared / Coefficient of Determination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In regression, error is mathematically written as -\n",
    "\n",
    "$$e_i = y_i - \\hat{y_i}$$\n",
    "\n",
    "where\n",
    "\n",
    "* $y_i$ is an actual value\n",
    "* $\\hat{y_i}$ is the predicted value\n",
    "\n",
    "---\n",
    "\n",
    "2.  Total sum of squares \n",
    "\n",
    "$$\\implies \\text{SS}_{\\text{Total}} = \\frac{1}{n} \\sum_{i = 1}^n (y_i - \\bar{y})^2$$\n",
    "\n",
    "where\n",
    "\n",
    "* $y_i$ is an actual value\n",
    "* $\\bar{y}$ is the mean of all $y_i$'s\n",
    "\n",
    "---\n",
    "\n",
    "3. Sum of squares of residuals\n",
    "\n",
    "$$\\implies \\text{SS}_{\\text{Res}} = \\sum_{i = 1}^n (y_i - \\hat{y_i})^2 = \\sum_{i = 1}^n e_i^2$$\n",
    "\n",
    "where\n",
    "\n",
    "* $y_i$ is an actual value\n",
    "* $\\hat{y_i}$ is the predicted value\n",
    "\n",
    "---\n",
    "\n",
    "4. Coefficient of determination or $\\text{R}^2$\n",
    "\n",
    "$$\\text{R}^2 = \\bigg[1 - \\frac{\\text{SS}_{\\text{Res}}}{\\text{SS}_{\\text{Total}}}\\bigg]$$\n",
    "\n",
    "* **Case - 1**\n",
    "    - $e_i = 0 \\implies \\text{SS}_{\\text{Res}} = 0 \\implies \\text{R}^2 = 1 \\implies \\text{best value}$\n",
    "* **Case - 2**\n",
    "    - $\\text{SS}_{\\text{Res}} < \\text{SS}_{\\text{Total}} \\implies \\text{R}^2 = (0 \\ \\text{to} \\ 1) \\implies \\text{often observed}$\n",
    "    - Closer the $\\text{R}^2$ is to $1$, the better it is\n",
    "    - Closer the $\\text{R}^2$ is to $0$, the worst it is\n",
    "* **Case - 3**\n",
    "    - $\\text{SS}_{\\text{Res}} = \\text{SS}_{\\text{Total}} \\implies \\text{R}^2 = 0 \\implies \\text{model is same as Simple Mean Model}$\n",
    "* **Case - 4**\n",
    "    - $\\text{SS}_{\\text{Res}} > \\text{SS}_{\\text{Total}} \\implies \\text{R}^2 < 0 \\implies \\text{model is worse than Simple Mean Model}$\n",
    "\n",
    "---\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "* $\\text{R}^2$ is not very robust to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Absolute Deviation (MAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There can be scenarious in which the any random element of error list can be very large and that can mess the metric ($\\text{R}^2$).\n",
    "* To avoid this, we compute `MAD` of all errors since median is very robust to outliers.\n",
    "* First, compute the median of errors and then check `MAD`. If `MAD` is close to median of errors then model is good else it is bad.\n",
    "\n",
    "$$\\text{MAD} = \\text{Med}\\big(\\big|e_i - \\text{Med}(E)\\big|\\big)$$\n",
    "\n",
    "where\n",
    "\n",
    "* $E = [e_1, e_2, e_3, \\dots, e_n]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can also plot the `PDF` and `CDF` curves for the error list and determine the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use which performance metrics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Log-Loss** → If we want probabilities of classes.\n",
    "\n",
    "* **Accuracy** → If classes are balanced.\n",
    "\n",
    "* **Precision** → If classes are imbalanced and we are more concerned about only `True positive`.\n",
    "\n",
    "* **Recall** → If we are more concerned about `False negative` and `True positive`.\n",
    "\n",
    "* **F1 score** → It is a balance between precision and recall.\n",
    "\n",
    "* **ROC_AUC** → If our concern is both classes (`True negative` and `True positive`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
