{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In probability theory, **conditional probability** is a measure of the probability of an event occurring, given that another event (by assumption, presumption, assertion or evidence) has already occurred. \n",
    "\n",
    "* If the event of interest is **A** and the event **B** is known or assumed to have occurred, \"the conditional probability of A given B\", or \"the probability of A under the condition B\", is usually written as $P(A | B)$, or sometimes $P_{B}(A)$ or $P(A / B)$.\n",
    "\n",
    "<img src=\"https://www.onlinemathlearning.com/image-files/conditional-probability-formula.png\">\n",
    "\n",
    "**Credits** - Image from Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two events **A** and **B** are said to be independent iff $P(A | B) = P(A)$ and $P(B | A) = P(B)$.\n",
    "\n",
    "* **A** : getting the value of 6 in die_1 throw → $(D_1 = 6)$\n",
    "* **B** : getting the value of 3 in die_2 throw → $(D_2 = 3)$\n",
    "\n",
    "Here, event **B** has nothing to do with the occurrence of event **A**. Viceversa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://keydifferences.com/wp-content/uploads/2016/05/mutually-exclusive-vs-independent-event.jpg\">\n",
    "\n",
    "**Credits** - Image from Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutually Exclusive Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two events **A** and **B** are said to be mutually exclusive iff $P(A | B) = 0 = P(B | A)$\n",
    "\n",
    "* **A** : getting the value of 6 in die_1 throw → $(D_1 = 6)$\n",
    "* **B** : getting the value of 3 in die_1 throw → $(D_2 = 3)$\n",
    "\n",
    "Here, $P(A \\cap B) = 0$ and hence **A** and **B** are mutually exclusive events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Theorem with Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have two events such as **A** and **B** then\n",
    "\n",
    "$$P(A | B) = \\frac{P(B | A) P(A)}{P(B)}; \\ \\text{if} \\ P(B) \\neq 0$$\n",
    "\n",
    "Here\n",
    "\n",
    "* $P(A | B) \\implies \\text{Posterior}$\n",
    "* $P(B | A) \\implies \\text{Likelihood}$\n",
    "* $P(A) \\implies \\text{Prior}$\n",
    "* $P(B) \\implies \\text{Evidence}$\n",
    "\n",
    "---\n",
    "\n",
    "**Proof**\n",
    "\n",
    "By definition w.k.t\n",
    "\n",
    "$$P(A | B) = \\frac{P(A \\cap B)}{P(B)} \\ or \\ \\frac{P(A, B)}{P(B)} \\rightarrow (1)$$\n",
    "\n",
    "Now, $(A \\cap B) = (B \\cap A)$. Using this, $(1)$ can be written as\n",
    "\n",
    "$$P(A | B) = \\frac{P(B \\cap A)}{P(B)} \\ or \\ \\frac{P(B, A)}{P(B)} \\rightarrow (2)$$\n",
    "\n",
    "Also, by definition w.k.t\n",
    "\n",
    "$$P(B | A) = \\frac{P(B \\cap A)}{P(A)}$$\n",
    "$$P(A)P(B | A) = P(B \\cap A) \\rightarrow (3)$$\n",
    "\n",
    "Now, substituting $(3)$ in $(2)$, we get\n",
    "\n",
    "$$P(A | B) = \\frac{P(B | A)P(A)}{P(B)}$$\n",
    "\n",
    "Hence proved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Algorithm\n",
    "\n",
    "* Refer to → https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multi-class classification problem we can extend Bayes Theorem as \n",
    "\n",
    "$$P(C_k | X) = \\frac{P(C_k)P(X | C_k)}{P(X)} \\rightarrow (1)$$\n",
    "\n",
    "where\n",
    "\n",
    "* $C_k \\rightarrow \\{1, 2, 3, \\dots, k\\}$ → classification labels\n",
    "* $X \\rightarrow$ Data in `n` dimentions $\\implies \\{x_1, x_2, x_3, \\dots, x_n\\}$\n",
    "\n",
    "From $(1)$, take numerator and write as $P(C_k, x_1, x_2, \\dots, x_n)$ since $P(C_k)P(X | C_k) = P(C_k, X) \\ \\text{or} \\ P(C_k \\cap X)$\n",
    "\n",
    "By applying chain rule, we can have\n",
    "\n",
    "$\\implies P(C_k, x_1, x_2, \\dots, x_n)$\n",
    "* $= P(x_1, x_2, \\dots, x_n, C_k)$\n",
    "* $= P(x_1 | x_2, \\dots, x_n, C_k)P(x_2, x_3, \\dots, x_n, C_k)$\n",
    "* $= P(x_1 | x_2, \\dots, x_n, C_k)P(x_2 | x_3, \\dots, x_n, C_k)P(x_3, x_4, \\dots, x_n, C_k)$\n",
    "* $\\dots$\n",
    "* $= P(x_1 | x_2, \\dots, x_n, C_k)P(x_2 | x_3, \\dots, x_n, C_k) \\dots P(x_{n-1} | x_n, C_k)P(x_n | C_k)P(C_k)$\n",
    "\n",
    "$$P(C_k, x_1, x_2, \\dots, x_n) = P(x_1 | x_2, \\dots, x_n, C_k)P(x_2 | x_3, \\dots, x_n, C_k) \\dots P(x_{n-1} | x_n, C_k)P(x_n | C_k)P(C_k) \\rightarrow (2)$$\n",
    "\n",
    "By assuming features to be conditionally independent, we get\n",
    "\n",
    "$$P(x_i | x_{i + 1}, \\dots, x_n, C_k) = P(x_i | C_k) \\rightarrow (3)$$\n",
    "\n",
    "Thus, by $(2)$ and $(3)$ we can derive\n",
    "\n",
    "$\\implies P(C_k | X)$\n",
    "* $\\propto P(C_k, x_1, x_2, \\dots, x_n)$\n",
    "* $\\propto P(C_k)P(x_1 | C_k)P(x_2 | C_k) \\dots P(x_n | C_k)$\n",
    "* $\\propto P(C_k) \\prod_{i=1}^n P(x_i | C_k)$\n",
    "\n",
    "$$P(C_k, x_1, x_2, \\dots, x_n) \\propto P(C_k) \\prod_{i=1}^n P(x_i | C_k) \\rightarrow (4)$$\n",
    "\n",
    "Putting $(4)$ in $(1)$\n",
    "\n",
    "$$P(C_k | X) = \\frac{P(C_k) \\prod_{i=1}^n P(x_i | C_k)}{P(X)} \\rightarrow (5)$$\n",
    "\n",
    "With the help of `maximum a-posteriori` rule, we can predict the classification label $(\\hat{y})$\n",
    "\n",
    "$$\\hat{y} = \\text{argmax}_{k \\in \\{1, 2, \\dots, k\\}} P(C_k) \\prod_{i=1}^n P(x_i | C_k)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical Implementation of Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Refer to → http://shatterline.com/blog/2013/09/12/not-so-naive-classification-with-the-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes for Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Given an email, NaiveBayes works really well in classifying whether an email is spam or not.\n",
    "* Review calssification → positive, negative, and neutral.\n",
    "* For test classification tasks, NaiveBayes is heavily used because of its simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is a technique that helps tackle the problem of zero probability in the Naive Bayes machine learning algorithm. \n",
    "\n",
    "* It uses something called higher alpha values that will push the likelihood towards a value of 0.5, i.e., the probability of a word equal to 0.5 for both the positive and negative reviews.\n",
    "\n",
    "$$P(w^1 | y = 1) = \\frac{0 + \\alpha}{N + k\\alpha}$$\n",
    "\n",
    "where\n",
    "* $\\alpha \\rightarrow$ 1 (typically, it is taken only 1 to represent `add one smoothing`)\n",
    "* $k \\rightarrow$ number of possible values that $w^1$ can take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-Probabilities for Numerical Stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we continuously multiply the probabilities for each class, if suppose we had 100 probabilities to compute, it is sure that we will encounter the problem of numerical stability.\n",
    "* To avoid that, it is better to consider the logarithm of each probability.\n",
    "\n",
    "**Basic Fundamentals of Logarithms (log() is a monotonous function)**\n",
    "\n",
    "* $\\log(ab) = \\log(a) + \\log(b)$\n",
    "* $\\log(a^b) = b\\log(a)$\n",
    "\n",
    "w.k.t\n",
    "\n",
    "$$\\implies P(C_k | X) = P(C_k) \\prod_{i=1}^n P(x_i | C_k) \\rightarrow (1)$$\n",
    "\n",
    "applying $\\log$ on both sides of $(1)$\n",
    "\n",
    "$$(1) \\implies \\log \\big[P(C_k | X) \\big] = \\log \\big[P(C_k) \\big] + \\sum_{i=1}^n \\log \\big[P(x_i | C_k) \\big]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = list(range(1, 20))\n",
    "y = list(map(math.log, x))\n",
    "# z = list(map(math.exp, x))\n",
    "\n",
    "plt.plot(x, y, 'o--g')\n",
    "# plt.plot(x, z, 'o--r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Naive Bayes\n",
    "    - high bias → underfitting\n",
    "    - high variance → overfitting (a small change in the training data results to a drastic change in the model)\n",
    "\n",
    "* **case - 1**\n",
    "    - When $\\alpha$ is very small (0), there will be high variance. Therefore, it leads to overfitting.\n",
    "\n",
    "* **case - 2**\n",
    "    - When $\\alpha$ is very large, there will be high bias. Therefore, it leads to underfitting.\n",
    "\n",
    "The balance tradeoff is completely dependent on the value of $\\alpha$. We can find the righ $\\alpha$ by simple cross validation method (something similar to K-NN).\n",
    "\n",
    "**Note**\n",
    "\n",
    "* $\\alpha$ in Naive Bayes and $k$ in K-NN are called hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance and Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The importance of the data value is taken based on probability. If the probability is high then it is retained else it is removed.\n",
    "\n",
    "* Feature importance can be obtained or determined directly from the model itself (with the help of likelihood)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In an imbalanced data, the majority class data has upper hand and viceversa. It can be problematic as the model may tend to give predictions pertaining to only majority class.\n",
    "\n",
    "* To resolve this, we can do upsampling or downsampling and try to get balanced data.\n",
    "\n",
    "* When applied laplace smoothing, the $\\alpha$ value impacts the minority class a alot.\n",
    "\n",
    "---\n",
    "\n",
    "* Let's say we have probabilities for minority class and majority like this following -\n",
    "\n",
    "    - Minority → $\\frac{2}{100}$ → 2%\n",
    "    - Majority → $\\frac{18}{900}$ → 2%\n",
    "* Let $\\alpha$ be 10. Now, by applying laplace smoothing, we get -\n",
    "    \n",
    "    - Minority → $\\frac{2 + 10}{100 + 20}$ → 10%\n",
    "    - Majority → $\\frac{18 + 10}{900 + 20}$ → 3.04%\n",
    "\n",
    "* Clearly, minority class has got influenced more than majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To handle outliers in the data while applying Naive Bayes, we shall take the following measures -\n",
    "    - Use laplace smoothing (as it works for outliers as well).\n",
    "    - Remove those data values whose occurrence is very less (set a threshold for solving it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In case of real-valued data, to find the probability of each data value with respect to target variable, it is `assumed` that the feature column follows Gaussian Distribution. If it is so, we can easily find the probabilities with the help of contingency (pdf) table.\n",
    "\n",
    "* Therefore, this model becomes Gaussian Naive Bayes. The likelihood is computed assuming that the feature is Normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity and Distance Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Naive Bayes cannot classify data based on distance or similarity matrix (as K-NN classifies).\n",
    "* It is a probability based method which needs a column as input.\n",
    "* The formula\n",
    "\n",
    "$$P(C_k | X) = P(C_k) \\prod_{i = 1}^n P(x_i | C_k)$$\n",
    "\n",
    "* Here $x_i$ is nothing but a feature or column."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
