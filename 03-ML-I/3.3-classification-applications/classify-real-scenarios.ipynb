{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important source\n",
    "\n",
    "* https://christophm.github.io/interpretable-ml-book/intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> KNN gets effected when the data is imbalanced and column standardization is one important technique to be followed before proceeding with the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced data vs Imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A **balanced data** has an equal number of observations for all possible level of combinations.\n",
    "* If there is a high disparity of observations for all possible level of combinations is called **imbalanced data**.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/450/1*zsyN08VVrgHbAEdvv27Pyw.png\">\n",
    "\n",
    "**Credits** - Image from Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to work around imbalanced data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Undersampling**\n",
    "\n",
    "    * The simplest undersampling technique involves randomly selecting examples from the majority class and deleting them from the training dataset. This is referred to as random undersampling.\n",
    "    * We make sure that after selecting the random sample, the size remains same to that of minority class.\n",
    "    * The model will end up having very small amount of data.\n",
    "\n",
    "* **Oversampling**\n",
    "    \n",
    "    * The simplest oversampling technique involves randomly selecting examples from minoroty class with replacesments from the training dataset. This is referred to as random oversampling.\n",
    "    * We make sure that after sampling (random) with replacement, the size remains same to that of majority class.\n",
    "    * The model will end up having sufficient amount of data for effective training.\n",
    "    * **Extrapolation** - Creating new data by considering all the data values of a certain class. These points are called synthetic points.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/725/1*7xf9e1EaoK5n05izIFBouA.png\">\n",
    "\n",
    "**Credits** - Image from Internet\n",
    "\n",
    "<br>\n",
    "\n",
    "> _**With an imbalanced data the accuracy (metrics) can be high and here the `accuracy_score` doesn't work effectively.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Binary Classifier → $y_i \\in \\{0, 1\\}$\n",
    "* Multi-class Classifier → $y_i \\in \\{0, 1, 2, \\dots, 9\\} \\implies \\text{MNIST data set}$\n",
    "\n",
    "> KNN can easily be extented to multi-class classifier. It uses both majority voting and probabilistic methods to classify the data.\n",
    "\n",
    "> Logistic regression is used for binary classification. Given a multi-class classfication problem, can we convert it into binary classification problem such as - from $\\text{f}(x) \\rightarrow \\{0, 1\\}$ to $\\text{g}(x) \\rightarrow \\{0, 1, 2, 3, \\dots, C-1\\}$ (considering there are $C$ classes).\n",
    "\n",
    "* Imagine the $y_i \\in \\{0, 1, 2, 3, \\dots, C-1\\}$, we need to develop a model in such a way that it classifies the data totally $C$ times. Basically, we are going to train $C$ models.\n",
    "\n",
    "    * Divide ($D_n$) in two part (to replicate binary classification problem)\n",
    "        - $D_n \\rightarrow \\{(x_i, y_i) | y_i = 0\\}$\n",
    "        - $D_n \\rightarrow \\{(x_i, y_i) | y_i \\neq 0\\}$\n",
    "    * Divide ($D_n$) in two part (to replicate binary classification problem)\n",
    "        - $D_n \\rightarrow \\{(x_i, y_i) | y_i = 1\\}$\n",
    "        - $D_n \\rightarrow \\{(x_i, y_i) | y_i \\neq 1\\}$\n",
    "    * . . .\n",
    "    * Divide ($D_n$) in two part (to replicate binary classification problem)\n",
    "        - $D_n \\rightarrow \\{(x_i, y_i) | y_i = C-1\\}$\n",
    "        - $D_n \\rightarrow \\{(x_i, y_i) | y_i \\neq C-1\\}$\n",
    "\n",
    "> This technique is called _**1 VS Rest**_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Test Set differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When data changes over time, we need to be very careful in doing time based splitting.\n",
    "\n",
    "**Q) How to determine if the data is changing over time?**\n",
    "\n",
    "* We can do this by plotting $D_{Train}$ and $D_{Test}$ values.\n",
    "\n",
    "**Q) Test if $D_{Train}$ and $D_{Test}$ have different distributions?**\n",
    "\n",
    "* Nomally in TBS we divide $D_n$ into two sets\n",
    "    - $D_{Train} \\rightarrow (x_i, y_i) \\implies (x_i^1, y_i^1)$\n",
    "    - $D_{Test} \\rightarrow (x_i, y_i) \\implies (x_i^1, y_i^1)$\n",
    "* In order to do the above, we shall create a new data set $D_n^1$ such that\n",
    "    - $D_{Train}^1$ will have $y_i^1 = 1; x_i^1 = \\text{concat}(x_i, y_i)$ in $D_{Train}$\n",
    "    - $D_{Test}^1$ will have $y_i^1 = 0; x_i^1 = \\text{concat}(x_i, y_i)$ in $D_{Test}$\n",
    "* After doing so, build a binary classifier on $D_n^1$\n",
    "* We then ask the classifier to separate the points in two classes.\n",
    "    - If they get well separated, they are highly dissimilar.\n",
    "    - Else, they are sort of similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When `k` is small, outliers can easily impact the model.\n",
    "* When we have a situation where for `10 fold` cross validation we have accuracies of all the `k`'s as -\n",
    "    - <b><p style=\"color:red;\">k = 1 → 97%</p></b>\n",
    "    - k = 2 → 97%\n",
    "    - k = 3 → 97%\n",
    "    - k = 4 → 97%\n",
    "    - <b><p style=\"color:green;\">k = 5 → 97%</p></b>\n",
    "    - k = 6 → 95%\n",
    "    - k = 7 → 92%\n",
    "    - . . .\n",
    "    - In this scenario, it is always better to choose larger `k` i.e., `k = 5` because it is less prone to outliers, whereas `k = 1` is very prone to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Outlier Factor (Simple Solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's say that we have two clusters such as $C_1$, $C_2$ and outliers such as $x_1$ and $x_2$ as shown in the below figure.\n",
    "\n",
    "![lof](https://user-images.githubusercontent.com/63333753/117539281-8ebe9580-b027-11eb-8f70-e97040cf752b.png)\n",
    "\n",
    "* Here red lines show the average distance between any random point $x_i$ capturing the distances between the point and it $5$ nearest neighbors. We do the same thing with outlier points.\n",
    "\n",
    "**Q) Given this, how do we detect the outliers?**\n",
    "\n",
    "1. From every point $x_i$, compute its $(k = 5)$ NN.\n",
    "2. Compute average distance from $x_i$ to is `5-NN`.\n",
    "3. Sort $x_i$'s by the average distances.\n",
    "    - If average distance is high, then the point is outlier.\n",
    "\n",
    "This has to be performed cluster wise something known as local density. But the ultimate question still remains unanswered- \n",
    "\n",
    "* **How do we capture the local density?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-distance and Neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Distance to the $k^{th}$ nearest neighbor of $x_i$ from $x_i$ is called k-distance.\n",
    "\n",
    "* Set of all points that belong to the K-NN of $x_i$ is called Neighborhood $N(x_i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reachability-Distance(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simple, the reachability distance is written as -\n",
    "\n",
    "$$\\text{reach_distance}(x_i, x_j) = \\text{max}\\big[\\text{k_distance}(x_j), \\text{dist}(x_i, x_j)\\big]$$\n",
    "\n",
    "where\n",
    "\n",
    "* $\\text{k_distance}(x_j) \\rightarrow $ distance of $K^{th}$-NN of $x_j$ from $x_j$\n",
    "    - If $(k = 5)$, then $\\text{k_distance}(x_j)$ is the distance of the fifth farthest (nearest) point\n",
    "* $\\text{dist}(x_i, x_j) \\rightarrow $ actual distance between $x_i$ and $x_j$\n",
    "\n",
    "**Note**\n",
    "\n",
    "* If $x_i \\in N(x_i)$ then $\\text{reach_distance}(x_i, x_j)$ is $\\text{k_distance}(x_j)$.\n",
    "\n",
    "![reach_distance1](https://user-images.githubusercontent.com/63333753/117561759-418a0480-b0b7-11eb-9093-6030230b2c49.png)\n",
    "\n",
    "* Otherwise, $\\text{reach_distance}(x_i, x_j)$ is $\\text{dist}(x_i, x_j)$.\n",
    "\n",
    "![reach_distance2](https://user-images.githubusercontent.com/63333753/117561760-4353c800-b0b7-11eb-9eb6-863cbdf67715.png)\n",
    "\n",
    "> _**This concept helps how to get around with the problem of two clusters...**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Reachability Density (A) → lrd(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\text{lrd}$ is used to measure the density.\n",
    "\n",
    "> $\\text{lrd}(x_i) \\implies \\text{Inverse of average reachability distance of a point from its neighbors.}$\n",
    "\n",
    "> $$\\text{lrd}(x_i) \\implies \\frac{1}{\\sum_{x_j \\in N(x_i)} \\bigg\\{ \\frac{\\text{reach_dist}(x_i, x_j)}{|N(x_i)|} \\bigg\\} } = \\frac{|N(x_i)|}{\\sum_{x_j \\in N(x_i)} \\big\\{\\text{reach_dist}(x_i, x_j)\\big\\}}$$\n",
    "\n",
    "**Note**\n",
    "\n",
    "* $|S| \\rightarrow$ Number of elements in the set $S$ (without duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Outlier Factor (A) → LOF(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `LOF` is inspired from `KNN`.\n",
    "\n",
    "**Formula**\n",
    "\n",
    "$$\\text{LOF}(x_i) = \\frac{\\sum_{x_j \\in N(x_i)} \\text{lrd}(x_j) }{|N(x_i)|} * \\frac{1}{\\text{lrd}(x_i)}$$\n",
    "\n",
    "**Sample Image**\n",
    "\n",
    "<img src=\"https://antonsruberts.github.io/assets/images/anomaly_ga/lof.png\">\n",
    "\n",
    "**Credits** - Image from Internet\n",
    "\n",
    "**Note**\n",
    "\n",
    "* If $\\text{LOF}(x_i)$ is large, then $x_i$ is an outlier.\n",
    "    - It happens when density (lrd) of a point $x_i$ is small, compared to its neighbors (Inverse will be large).\n",
    "* Otherwise, inlier.\n",
    "\n",
    "**Steps to compute $\\text{LOF}(x_i)$**\n",
    "\n",
    "* For each point $x_i$, compute $\\text{LOF}(x_i)$\n",
    "* Pick points with highest $\\text{LOF} \\implies$ outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The model which can give explanation is called an **interpretable model**.\n",
    "    - `Eg` → Why the model has said the class label to be `1` or `0`.\n",
    "* On the other hand, the model which cannot give explanation is called **black box model**.\n",
    "\n",
    "> _**KNN is interpretable when `d` is small and `k` is also small...**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "* Refer → https://www.analyticsvidhya.com/blog/2016/12/introduction-to-feature-selection-methods-with-an-example-or-how-to-select-the-right-variables/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Selecting which features are most important for the **classification** or **regression** problems. Sort the features by their importance and suitability for the problem statement.\n",
    "* This technique is very useful in understanding the model better and thus model interpretability increases.\n",
    "* Models like **Logistic Regression**, **Decision Trees**, can be really helpful to get the features based on their importance.\n",
    "    - `KNN` by default provide or get the important features.\n",
    "\n",
    "**Forward Feature Selection**\n",
    "\n",
    "* Imagine your data set is divided into two $[D_{\\text{Train}}, D_{\\text{Test}}]$ and the features are $\\{f_1, f_2, f_3, \\dots, f_d \\}$. Let's say we have a model (`KNN`) in which $[D_{\\text{Train}}, D_{\\text{Test}}]$ are passed.\n",
    "\n",
    "* Now, take each feature at a time and train the model using only that (one) feature and store the accuracy.\n",
    "    - Repeat this process for $d$ times.\n",
    "    - Let's say that the feature $f_{10}$ is giving highest accuracy.\n",
    "    - List of features $\\implies \\{f_1, f_2, \\dots, f_9, f_{11}, f_{12}, \\dots, f_d\\}$\n",
    "    - **Best feature** - $f_{10}$\n",
    "* Now, take each feature at a time and train the model using only that (one) along with the best feature that is selected in the previous step ($f_{10}$) and store the accuracy.\n",
    "    - Repeat this process for $(d - 1)$ times.\n",
    "    - Let's say that the feature $f_5$ is giving highest accuracy.\n",
    "    - List of features $\\implies \\{f_1, f_2, f_3, f_4, f_6, \\dots, f_9, f_{11}, f_{12}, \\dots, f_d\\}$\n",
    "    - **Best features** - $\\{f_{10}, f_5 \\}$\n",
    "* Repeat the whole process based on the threshold that is required to have best features and is sufficient to solve the given problem.\n",
    "* This technique of selecting features iteratively is called forward selection.\n",
    "* Time complexity is very large since we have to train the model $d$ times and decreases by $1$ iteratively.\n",
    "* **Model agnostic** - Not caring about the model and doing the process.\n",
    "\n",
    "**Backward Selection**\n",
    "\n",
    "* Takes all the features at a time and in every iteration, it removes each features and tracks the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Categorical & Numerical Features\n",
    "\n",
    "* Refer\n",
    "    - https://contactsunny.medium.com/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621\n",
    "    - https://towardsdatascience.com/choosing-the-right-encoding-method-label-vs-onehot-encoder-a4434493149b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Different ways of converting categorical data into numeric features**\n",
    "\n",
    "1. Simply convert the categorical data into number by replacing random numbers.\n",
    "\n",
    "2. Best solution for this is to do `one-hot-encoding` rather than giving artificial numbers.\n",
    "    - Imagine I have data such as `['black', 'brown', 'green', 'red']`. For this we can create five vectors.\n",
    "        - `black` → [1, 0, 0, 0]\n",
    "        - `brown` → [0, 1, 0, 0]\n",
    "        - `green` → [0, 0, 1, 0]\n",
    "        - `red` → [0, 0, 0, 1]\n",
    "\n",
    "3. If the number of distinct values for a categorical feature is large then `one-hot-encoding` can create sparse and large vectors.\n",
    "    - In that case, we can take mean value of `target` for each category and replace it in the entire data set. This is called `mean-replacement`.\n",
    "\n",
    "4. Use domain knowledge and convert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `NaN` Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values in the data occur due to various reasons. Some of them are -\n",
    "\n",
    "* Data Corruption\n",
    "* Collection Error\n",
    "\n",
    "**Q) How can we featurize the missing data?**\n",
    "\n",
    "* Strategies to fill the missing values\n",
    "    - Imputation\n",
    "        - Mean replacement\n",
    "        - Median replacement\n",
    "        - Mode replacement\n",
    "        - (If certain feature is categorical, then compute any of the above strategies based on class label or target variable)\n",
    "        \n",
    "    - Create a new feature of missing values after imputing. Generally, this new feature will comprise binary values -\n",
    "        - `1` → representing the value is missing\n",
    "        - `0` → representing the value is not missing.\n",
    "    - Model based imputation\n",
    "        - Create whichever column has missing as a `target` column and specifically in the test set. Use a machine learning model to predict the missing value.\n",
    "        - `KNN` is often used for model based imputation because of the neighborhood concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curse of Dimensionality\n",
    "\n",
    "* Refer → https://en.wikipedia.org/wiki/Curse_of_dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally when the dimensions of the data increases the problem arises.\n",
    "\n",
    "* In **Machine Learning**\n",
    "    - As the dimensions increase, the total number of data points increase exponentially.\n",
    "    - Let's say we have got binary (0, 1) features (3) → $f_1, f_2, f_3 \\implies 2^3 = 8$\n",
    "    - Similarly if we have $10$ features → $f_1, f_2, \\dots, f_{10} \\implies 2^{10} = 1024$\n",
    "    - With a fixed number of traning samples, the prediction power of a model decreases as the dimensions increase. This is called **Hughes Phenomenon**.\n",
    "\n",
    "* In **Distance Functions** (euclidean distance)\n",
    "    - The intuition of distances in `3D` is not valid in higher dimension spaces.\n",
    "        - In `1D`, `2D`, and `3D` the equation $\\frac{\\text{dist_max}(x_i) - \\text{dist_min}(x_i)}{\\text{dist_min}(x_i)} > 0$\n",
    "        - As `d` increases the above equation tends to $0$. This can be proved by limit concepts in mathematics.\n",
    "    - **Twist**\n",
    "        - If the data is **high dimensional** and **dense** → impact of dimensionality is high.\n",
    "        - If the data is **high dimensional** and **sparse** → impact of dimensionality is low.\n",
    "\n",
    "* In **Overfitting** & **Underfitting**\n",
    "    - As `d` increases, the chances of model getting overfitted in high.\n",
    "    - To solve this, we can make use of -\n",
    "        - **Forward Feature Selection** to pick the most useful subset of features.\n",
    "        - **PCA** and **T-SNE** can also be used to reduce the dimensions.\n",
    "\n",
    "**Intuitional Explanation**\n",
    "\n",
    "* Let's say you have a straight line 100 yards long and you dropped a penny somewhere on it. It wouldn't be too hard to find. You walk along the line and it takes two minutes.\n",
    "\n",
    "* Now let's say you have a square 100 yards on each side and you dropped a penny somewhere on it. It would be pretty hard, like searching across two football fields stuck together. It could take days.\n",
    "\n",
    "* Now a cube 100 yards across. That's like searching a 30-story building the size of a football stadium. Ugh.\n",
    "\n",
    "* The difficulty of searching through the space gets a *lot* harder as you have more dimensions. You might not realize this intuitively when it's just stated in mathematical formulas, since they all have the same \"width\". That's the curse of dimensionality. It gets to have a name because it is unintuitive, useful, and yet simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$\\text{Generalization Error (future data error)} = \\text{Bias}^2 + \\text{Var} + \\text{Irreducible Error}$$\n",
    "\n",
    "* **Bias** - Errors due to simplifying assumptions.\n",
    "    * If the bias is high, it means the model will underfit, otherwise not.\n",
    "* **Variance** - Represents, how much the model changes as training data changes.\n",
    "    * High variance model always leads to overfitting.\n",
    "* **Irreducible Errors** - Errors which cannot be further reduced.\n",
    "\n",
    "We have to tradeoff to find the moderate solution in which there is not much bias and less variance. This balancing of the model performance is always encouraged to apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
