{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "\n",
    "https://cs231n.github.io/ → from Stanford University\n",
    "\n",
    "### DL\n",
    "\n",
    "https://mohitjain.me/category/deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Cortex\n",
    "\n",
    "a biological inspiration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convolutional Neural Networks (CNN, ConvNets) extremely popular form neural networks.\n",
    "\n",
    "* CNN's have been specifically designed for visual tasks.\n",
    "    - mnist\n",
    "    - face detection\n",
    "    - object recognition\n",
    "        - machine learning\n",
    "        - computer vision (intersection of image processing and ml/ai)\n",
    "\n",
    "* **Why creating CNN instead of MLP?**\n",
    "    - lots of image processing and computer vision tasks have been inspired by biological findings\n",
    "        - there are some neurons that fire when presented specific objects ar specific angles\n",
    "        - there are some neurons that detect \n",
    "            - edges\n",
    "            - motion\n",
    "            - depth\n",
    "            - faces\n",
    "            - shapes\n",
    "    \n",
    "    - **biological inspiration**\n",
    "        <img src=\"https://www.frontiersin.org/files/Articles/34845/fpsyg-04-00124-HTML/image_m/fpsyg-04-00124-g001.jpg\">\n",
    "   \n",
    "   <br>\n",
    "   \n",
    "    - **CNN**\n",
    "        <img src=\"https://cdn-images-1.medium.com/fit/t/1600/480/1*vkQ0hXDaQv57sALXAJquxA.jpeg\">\n",
    "\n",
    "**Credits** - Images from Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution : Edge Detection\n",
    "\n",
    "edge detection is a primary visual cortex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Convolution**\n",
    "    - if given two matrices, convolution is a simple operation which includes element-wise multiplication following by addition\n",
    "    - a generalization of dot product\n",
    "    \n",
    "    <img src=\"https://miro.medium.com/max/728/1*Fr6Umze2waDjWVHB2yzT4A.png\">\n",
    "\n",
    "* **Edge Detection**\n",
    "    - we use `sobel` operator for detecting edges.\n",
    "        - **horizontal**\n",
    "            <pre>\n",
    "            s_h = [[+1, +2, +1],\n",
    "                   [ 0,  0,  0],\n",
    "                   [-1, -2, -1]]\n",
    "            </pre>\n",
    "        \n",
    "        - **vertical**\n",
    "            <pre>\n",
    "            s_v = [[+1,  0, -1],\n",
    "                   [+2,  0, -2],\n",
    "                   [+1,  0, -1]]\n",
    "            </pre>\n",
    "    \n",
    "    - let $A$ be the original image matrix\n",
    "    - let $G_x = S_h * A$ and $G_y = S_v * A$\n",
    "    - the convolution (result) is $G = \\sqrt{G_x^2 + G_y^2}$\n",
    "    - we perform convolution using the above operators with the sub-matrices of the image; resultant image contains edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2 as cv\n",
    "# import numpy as np\n",
    "\n",
    "# from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_image(image_mat):\n",
    "    s_min = 0; s_max = 255\n",
    "    image_min = image_mat.min()\n",
    "    image_max = image_mat.max()\n",
    "    scaled_image = ((image_mat - image_min) * (s_max - s_min)) / (image_max - image_min)\n",
    "    return scaled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_submatrices(image_mat, square_kernel_size=3):\n",
    "    orig_shape = image_mat.shape\n",
    "    pw = square_kernel_size - 2\n",
    "    \n",
    "    image_pad = np.pad(array=image_mat, pad_width=pw)\n",
    "    pimage_shape = image_pad.shape\n",
    "    h_reduce, w_reduce = (pimage_shape[0] - orig_shape[0]), (pimage_shape[1] - orig_shape[1])\n",
    "    \n",
    "    flat_submatrices = np.array([\n",
    "        image_pad[i:(i + 3), j:(j + 3)]\n",
    "        for i in range(pimage_shape[0] - h_reduce) for j in range(pimage_shape[1] - w_reduce)\n",
    "    ])\n",
    "    \n",
    "    return flat_submatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_operation(A, kernel):\n",
    "    return np.sum(np.multiply(A, kernel))\n",
    "\n",
    "def gradient_approximation(s_h, s_v):\n",
    "    return np.sqrt(s_h**2 + s_v**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_convolution(image_mat, scale=True, show_plot=True):\n",
    "    orig_shape = image_mat.shape\n",
    "    \n",
    "    mask = np.matrix([\n",
    "        [+1, +2, +1],\n",
    "        [ 0,  0,  0],\n",
    "        [-1, -2, -1]\n",
    "    ])\n",
    "    k_h = mask\n",
    "    k_v = mask.T\n",
    "    \n",
    "    flat_submatrices = break_submatrices(image_mat=image_mat)\n",
    "    \n",
    "    t_mat = []\n",
    "    for each_mat in flat_submatrices:\n",
    "        s_h = sobel_operation(A=each_mat, kernel=k_h)\n",
    "        s_v = sobel_operation(A=each_mat, kernel=k_v)\n",
    "        s_a = gradient_approximation(s_h=s_h, s_v=s_v)\n",
    "        # s_a = s_h + s_v\n",
    "        t_mat.append(s_a)\n",
    "    \n",
    "    eimage_mat = np.array(t_mat).reshape(orig_shape)\n",
    "    if scale:\n",
    "        eimage_mat = scale_image(image_mat=eimage_mat)\n",
    "    \n",
    "    if show_plot:\n",
    "        cmap_val = 'gray'\n",
    "        fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10, 20))\n",
    "\n",
    "        ax1.axis(\"off\")\n",
    "        ax1.title.set_text('Original')\n",
    "\n",
    "        ax2.axis(\"off\")\n",
    "        ax2.title.set_text(\"Sobel\")\n",
    "\n",
    "        ax1.imshow(image_mat, cmap=cmap_val)\n",
    "        ax2.imshow(eimage_mat, cmap=cmap_val)\n",
    "        plt.show()\n",
    "    \n",
    "    return eimage_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_mat = cv.imread(filename='valve_original.png')\n",
    "# image_mat = cv.cvtColor(src=image_mat, code=cv.COLOR_BGR2GRAY)\n",
    "# eimage_mat = sobel_convolution(image_mat=image_mat, scale=True, show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![valve_ed](https://user-images.githubusercontent.com/63333753/140903158-6953525e-bca9-46af-9427-85eebb475e60.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding & Strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Padding** → to retain the original size of the image after convolution, we pad the image with `0` values around the image.\n",
    "\n",
    "    - before padding\n",
    "        - $n \\ \\text{x} \\ n \\implies \\text{(conv with kernel)} \\implies (n - k + 1) \\ \\text{x} \\ (n - k + 1)$\n",
    "        - reduces the size of the matrix after convolution\n",
    "    - after padding\n",
    "        - $n \\ \\text{x} \\ n \\implies \\text{(conv with kernel + padding)} \\implies (n - k + 2p + 1) \\ \\text{x} \\ (n - k + 2p + 1)$\n",
    "            - where $p$ is the padding width\n",
    "            \n",
    "        - retains the size of the matrix after convolution\n",
    "\n",
    "* **Stride** → shifting the kernel along with the image matrix (to the exact size of the kernel) is called stride.\n",
    "    - helps reduce the size of the image\n",
    "    \n",
    "    - before striding\n",
    "        - $n \\ \\text{x} \\ n \\implies \\text{(conv with kernel)} \\implies (n - k + 1) \\ \\text{x} \\ (n - k + 1)$\n",
    "    - after striding\n",
    "        - $n \\ \\text{x} \\ n \\implies \\text{(conv with kernel + striding)} \\implies \\bigg[ \\text{floor}\\big(\\frac{n - k}{s}\\big) + 1 \\bigg] \\ \\text{x} \\ \\bigg[ \\text{floor}\\big(\\frac{n - k}{s}\\big) + 1 \\bigg]$\n",
    "            - where $s$ is striding step\n",
    "\n",
    "* Formulation in the case where both padding and striding is used -\n",
    "\n",
    "$$n \\ \\text{x} \\ n \\implies \\text{(conv with kernel + padding + striding)} \\implies \\bigg[ \\text{floor}\\bigg(\\frac{n - k + 2p}{s}\\bigg) + 1 \\bigg] \\ \\text{x} \\ \\bigg[ \\text{floor}\\bigg(\\frac{n - k + 2p}{s}\\bigg) + 1 \\bigg]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution : RGB Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A typical colored image is comprised of pixels (which are represented as RGB pixels).\n",
    "\n",
    "* A pixel is simply a number in the range of 0 to 255 for all R, G, and B.\n",
    "    - RGB are referred to as channels\n",
    "    - **R → Red → 0 to 255**\n",
    "    - **G → Green → 0 to 255**\n",
    "    - **B → Blue → 0 to 255**\n",
    "    \n",
    "    <img src=\"https://raw.githubusercontent.com/msameeruddin/Data-Analysis-Python/main/8_DA_Image_da/rgb_demo.png\">\n",
    "\n",
    "<br>\n",
    "\n",
    "* Some important colors and their RGB values -\n",
    "\n",
    "| Pixel | R | G | B |\n",
    "| --- | --- | --- | --- |\n",
    "| **White** | 255 | 255 | 255 |\n",
    "| **Red** | 255 | 0 | 0 |\n",
    "| **Green** | 0 | 255 | 0 |\n",
    "| **Blue** | 0 | 0 | 255 |\n",
    "| **Black** | 0 | 0 | 0 |\n",
    "| **Yellow** | 255 | 255 | 0 |\n",
    "\n",
    "* All colors → https://www.colorhexa.com/color-names.\n",
    "\n",
    "* A color image is simply known as a `tensor`.\n",
    "\n",
    "* **Convolution** in a color image (`tensor`) is similar to convolution in grayscale images.\n",
    "    - the kernel also becomes a `tenssor` in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layer\n",
    "\n",
    "convolution with multiple kernels followed by ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In classical image processing, we have kernels to perform various operations on images.\n",
    "\n",
    "* In a typical MLP, we try to learn the weights by backpropagation.\n",
    "\n",
    "* We know that a visual cortex consists of various layers to detect various things.\n",
    "\n",
    "* In a CNN, we try to learn kernels (for detecting various things).\n",
    "    - something similar we do in MLP\n",
    "    - kernels can be thought of weight matrices\n",
    "\n",
    "* A convolution layer has \n",
    "    - a input (3D tensor) with 3 channels of size (n * n * c)\n",
    "    - multiple kernels (all of them are same size) that is (k * k * c)\n",
    "    - after which we finally get 3D tensor of size (n * n * m)\n",
    "        - m corresponds to the number of kernels\n",
    "\n",
    "* **How many kernels to take?**\n",
    "    - it is a hyperparameter which needs to be tuned\n",
    "\n",
    "* **Process**\n",
    "    - we have a 3D tensor (RGB image) - input\n",
    "    - the input convolves with the kernel matrix (k * k * 3)\n",
    "    - then we perform elementwise ReLU activation function for each element\n",
    "    - the resultant matrix is of size (n * n * m)\n",
    "    \n",
    "    <img src=\"https://www.researchgate.net/profile/Devis-Tuia/publication/323273293/figure/fig1/AS:614258178002946@1523461970440/Schematic-of-the-first-convolutional-layer-of-a-CNN-This-layer-learns-Nf-5-filters-of.png\">\n",
    "\n",
    "**Credits** - Image from Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max-Pooling\n",
    "\n",
    "popular method in modern ConvNets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pooling is like a layers that can be added in the netowork.\n",
    "\n",
    "* **Inspiration**\n",
    "    - human beings can easily detect faces in the image easily\n",
    "    - they can detect faces at any location in the image → **location invariant**\n",
    "    - similarly, humans can easily detect eventhough the face is rotated (**rotation invariant**) or the face size is irregular (**scale invariant**)\n",
    "    - if we want to replicate the same features a neural network, we must use `max pooling`\n",
    "\n",
    "* Max-Pooling is again some sort of kernel which is doing kernel-trick.\n",
    "\n",
    "* The aim of max-pooling operation is to consider only max pixel from the size of the kernel with respect to original image. This has to be continued along the entire image by the help of striding.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/publication/333593451/figure/fig2/AS:765890261966848@1559613876098/Illustration-of-Max-Pooling-and-Average-Pooling-Figure-2-above-shows-an-example-of-max.png\">\n",
    "\n",
    "* Max-Pooling is a operation that must be applied after (convolution + ReLU), so as to efficiently solve the task.\n",
    "\n",
    "**Credits** - Image from Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Convolution + ReLU + Max-Pooling → CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Training : Optimization\n",
    "\n",
    "https://medium.com/@2017csm1006/forward-and-backpropagation-in-convolutional-neural-network-4dfa96d7b37e\n",
    "\n",
    "https://becominghuman.ai/back-propagation-in-convolutional-neural-networks-intuition-and-code-714ef1c38199"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In MLP, with the help of backpropagation, we can learn the appropriate weights and for optimization, we can use \n",
    "    - SGD\n",
    "    - AdaGrad\n",
    "    - Adam\n",
    "    - ...\n",
    "\n",
    "* Similarly, as long as the convolution layer and max-pooling layer, if the loss is differentiable with respect to loss, we can train and optimize the CNN.\n",
    "\n",
    "    - for sure the convolution layer is differentiable as it is very similar to MLP\n",
    "    - ReLU is also differentiable\n",
    "    - in max-pooling, for the max value, the derivative is 1. For the non-max value, the derivative is 1\n",
    "        - in backpropagation, we only pass the derivative back to the maximum value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet\n",
    "\n",
    "https://www.kaggle.com/blurredmachine/lenet-architecture-a-complete-guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/2625/1*1TI1aGBZ4dybR6__DI9dzA.png\">\n",
    "\n",
    "**Credits** - Image from Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Augmentation means adding some new stuff.\n",
    "\n",
    "* To make sure CNN models are good at their task of recognizing or understandind the visual data, the original data is augmented (or changed the structure or added some noise etc).\n",
    "    - flipping\n",
    "    - mirroring\n",
    "    - shifting\n",
    "    - rotation\n",
    "    - zooming (in and out)\n",
    "    - sheering (streching)\n",
    "    - blurring\n",
    "    - noising\n",
    "    - we can combine a lot of operations and come up with additional data\n",
    "    \n",
    "    <img src=\"https://www.kdnuggets.com/wp-content/uploads/cats-data-augmentation.jpg\">\n",
    "\n",
    "* **Why is data augmentation useful?**\n",
    "    - by data augmentation, we can get various types of `invariants` (as we get in max-pooling)\n",
    "    - the output doesn't change even if the input changes slightly\n",
    "    - if we have a small dataset, we can get a much larger dataset\n",
    "\n",
    "* Data augmentation is a popular technique especially in the field of computer vision.\n",
    "\n",
    "**Credits** - Image from Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras (CNN) Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convolution layers → https://keras.io/api/layers/convolution_layers/\n",
    "\n",
    "* Pooling layers → https://keras.io/api/layers/pooling_layers/\n",
    "\n",
    "* Keras core layers → https://keras.io/api/layers/core_layers/\n",
    "\n",
    "* LeNet code architecture → https://github.com/DustinAlandzes/mnist-lenet-keras/blob/master/lenet.py\n",
    "\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes, weightsPath=None):\n",
    "        # initialize the model\n",
    "        model = Sequential()\n",
    "\n",
    "        # first set of CONV => RELU => POOL\n",
    "        model.add(Convolution2D(20, 5, 5, border_mode=\"same\",\n",
    "            input_shape=(depth, height, width)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "        # second set of CONV => RELU => POOL\n",
    "        model.add(Convolution2D(50, 5, 5, border_mode=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "        # set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        # if weightsPath is specified load the weights\n",
    "        if weightsPath is not None:\n",
    "            model.load_weights(weightsPath)\n",
    "\n",
    "        return model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet\n",
    "\n",
    "http://euler.stat.yale.edu/~tba3/stat665/lectures/lec18/notebook18.html\n",
    "\n",
    "https://cs231n.github.io/convolutional-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AlexNet architecture\n",
    "\n",
    "    <img src=\"https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-31_01h31_40.jpg\">\n",
    "\n",
    "* Research paper → https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\n",
    "\n",
    "**Credits** - Image from Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGGNet\n",
    "\n",
    "https://arxiv.org/pdf/1409.1556.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Simplified version of AlexNet built by **Andrew Zisserman** and **team**.\n",
    "\n",
    "* Two types of network\n",
    "    - VGG-16 → 16 layered network\n",
    "    - VGG-19 → 19 layered network\n",
    "\n",
    "* Besides having different sizes of kernel (that we encounter in AlexNet), VGGNet comes with an idea of simplifying the layer by keeping same size (3 * 3) of kernel with stride 1 and paddinf as same for each convolution and max-pooling of size (2 * 2) and stride as 2.\n",
    "\n",
    "* Today, VGGNet is the default network for lots of computer vision tasks.\n",
    "\n",
    "* **Regularisation in VGG** : The training is regularised by weight decay (the L2 penalty multiplier set to `5*10^?4`) and dropout regularisation for the first two fully-connected layers (dropout ratio set to 0.5).\n",
    "\n",
    "* Architecture\n",
    "    - **workflow**\n",
    "    \n",
    "    <img src=\"https://qphs.fs.quoracdn.net/main-qimg-83c7dee9e8b039c3ca27c8dd91cacbb4\">\n",
    "    \n",
    "    - **visual workflow**\n",
    "    \n",
    "    <img src=\"https://qphs.fs.quoracdn.net/main-qimg-ba81c87204be1a5d11d64a464bca39eb\">\n",
    "\n",
    "**Credits** - Images from Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet (Residual Network)\n",
    "\n",
    "https://arxiv.org/pdf/1512.03385.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The problem with the `plain networks` (like VGGNet) is that, as the number of layers increase, both the training error and test error (even after many many iterations) happens to be worse comapred with the less layered network.\n",
    "    - this case occurred even after using `dropouts` and `ReLU` etc\n",
    "\n",
    "* The building block to solve the above problem is below.\n",
    "\n",
    "![resnet-building-block](https://user-images.githubusercontent.com/63333753/141275207-166a9437-4a4a-42ae-b144-8a73a34e8913.png)\n",
    "\n",
    "* We use the ideology of **skip connection** and thus get terrific results which solves the problem.\n",
    "\n",
    "> $\\text{ReLU}\\big[\\ \\text{ReLU} \\ (x)\\ \\big] = \\text{ReLU} \\ (x)$\n",
    "\n",
    "* **Key Takeaways**\n",
    "\n",
    "    - adding additional/new layers would not hurt performance as regularization will skip over them\n",
    "    - if new layers are useful even in the presence of regularization, the weights or kernels will be non-zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception Network\n",
    "\n",
    "https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "\n",
    "https://cs231n.github.io/transfer-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Task** : Let's say that the task here is to classify dogs from cats. Of course, for solving this we can build a ConvNet (2 class classifier)\n",
    "\n",
    "* **Idea** : Instead of building a convolutional neural network from scratch, what if we can reuse the existing models (VGG-16) which is trined on a different dataset.\n",
    "    - Can the **learning** be **transferred** from one dataset to a different dataset to solve a different task altogether?\n",
    "    \n",
    "    <img src=\"https://datascience.aero/wp-content/uploads/2020/03/transferlearning-119.jpg\">\n",
    "\n",
    "> Keras has the complete model (VGG-16) trained on ImageNet dataset - (pre-trained) models.\n",
    "\n",
    "* **Case - 1**\n",
    "    - we can use the bottleneck features (features that come before the flattening layer)\n",
    "        - we can train a simple linear (classifer) model on these bottleneck features\n",
    "    - we use the existing model as a feature engineering tool\n",
    "    - when the new dataset is very similar to ImageNet and is very small, then this technique has to be implemented\n",
    "\n",
    "* **Case - 2**\n",
    "    - we can simply finetune the last layers of the neural network (VGG-16) using the new dataset and freeze the earlier layers\n",
    "        - while finetunning the model, we should ensure that the learning rate is small so as to make sure that the weights do not change too drastically\n",
    "    - when the new dataset is medium-sized and also very similar to ImageNet, then this technique has to be implemented\n",
    "\n",
    "* **Case - 3**\n",
    "    - use the existing model (VGG-16) as an initialization model and finetune the whole model for the task\n",
    "        - of course the learning rate should be small\n",
    "    - when the new dataset is large and also very similar to ImageNet, then finetune the complete network\n",
    "\n",
    "* **Case - 4**\n",
    "    - dump the existing the models and build a new model from scratch\n",
    "        - **NOT RECOMMEDED AT ALL**\n",
    "    - when the new dataset is small and not similar to ImageNet, then the output of the earlier layers has to be used as features for the new task\n",
    "\n",
    "\n",
    "**Credits** - Image from Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cats VS Dogs\n",
    "\n",
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
